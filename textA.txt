\section{提案手法}
\label{sec:method}

本研究では、小規模モデル（SLM）の数学的推論能力を最大化するため、(1) 同規模の指導モデル群を用いたサンプリングフリーなアノテーションによるプロセス報酬学習、および (2) ステップごとのスコア分布に基づく学習ベース集計、の 2 段階からなるフレームワークを提案する.

\subsection{確率ベースのプロセス報酬学習}
従来の PRM 学習では、モデル自身のサンプリングに基づくモンテカルロ推定が必要であったが、本手法では指導モデル（Instruct Models）の確信度を蒸留することで、計算コストを削減しつつ高品質なプロセス報酬を学習する.

\paragraph{確信度の定義とアンサンブル} 
数学問題$x$ に対する推論パス $s = (s_1, ..., s_T)$ の各ステップ $s_t$ の品質を評価するために、同程度のサイズ帯を持つ複数の指導モデル集合 $\mathcal{M} = \{M_1, ..., M_K\}$ を利用する.
各モデル $M_k$ に対し、文脈 $x, s_{1:t}$ の直後に正解を強制するフレーズを付与し、正解トークン（Ground Truth Token）の生成確率 $P_k(y_{GT} | x, s_{1:t})$ を計算する.
本手法では、単一モデルのバイアスを軽減するため、複数モデルの平均確信度 $P_{avg} = \frac{1}{K} \sum P_k$ を教師信号として用いる（比較対象として単一モデルを用いる場合もある）.

\paragraph{Log-Sigmoid 変換による報酬設計}
指導モデルから得られる確信度は、特に不正解ステップにおいて極めて小さな値をとるため、回帰学習に適したスケールに変換する必要がある.
そこで、対数確率に対し、データの分布特性に応じた中心化を行う Log-Sigmoid 変換を導入する.
ステップ $s_t$ に対する報酬 $r_t$ を以下の式で定義する.
\begin{equation}
r_t = \sigma(\alpha \cdot (\log P_{avg}(s_t) - \tau))
\end{equation}
ここで $\sigma$ はシグモイド関数、$\alpha, \tau$ は分布の形状に応じて決定されるハイパーパラメータである.
生徒モデル（PRM）は、この $r_t$ を予測する回帰タスクとして学習する.

\subsection{学習ベースのスコア集計}

推論時（Best-of-N 探索）において、PRM は推論パスに対して可変長のステップスコア列 $V = (v_1, v_2, ..., v_T)$ を出力する.
単純な Min や Mean といった集計手法は外れ値（ノイズ）に弱いため、本研究ではスコア列全体の特徴を用いた学習ベース集計を行う.

\paragraph{特徴量抽出}
PRMの出力であるスコア列 $V$ から以下の特徴量ベクトル $\phi(V)$ 作成する.

\begin{itemize}
    \item 基本統計量: 最小値、平均値、最大値、標準偏差
    \item 端点スコア: 始点・終点のスコア
    \item 局所的整合性: 最後の3ステップの最小値
    \item その他: ステップ数、およびロジットの総和
\end{itemize}

\paragraph{集計モデル}
抽出された特徴量 $\phi(V)$ を入力とし、そのパスが正解か否かを 2 値分類する軽量な分類器（勾配ブースティング木等）を学習させ、その出力確率をパスの最終評価値とする.
