\section{提案手法}
\label{sec:method}

本研究では、小規模モデル（SLM）の数学的推論能力を最大化するため、(1) 複数の指導モデルを用いたサンプリングフリーなアノテーションによるプロセス報酬学習、および (2) ステップごとのスコア分布に基づく学習ベース集計、の 2 段階からなるフレームワークを提案する.

\subsection{確率ベースのプロセス報酬学習}
既存の自動 PRM 構築手法（Math-Shepherd 等）は、ラベル生成のために膨大なモンテカルロ・ロールアウトを必要としていた.
これに対し、本手法では既存の指導モデル（Instruction-tuned Models）を「評価者」として利用し、その確信度を蒸留することで、計算コストを劇的に削減しつつ高品質なプロセス報酬を学習する.

\paragraph{Prompted Forcing による確信度抽出}
数学問題 $x$ に対する推論パス $s = (s_1, ..., s_T)$ の各ステップ $s_t$ の品質を評価するために、同程度のサイズ帯を持つ指導モデル集合 $\mathcal{M} = \{M_1, ..., M_K\}$ を利用する.
単純に正解トークンの確率を計算するだけでは、モデルの生成傾向に依存し評価が不安定となるため、正解を強制するプロンプト（Prompted Forcing）」を導入する.
具体的には、各モデル $M_k$ に対し、文脈 $x, s_{1:t}$ の直後に「したがって、答えは（Therefore, the answer is \boxed{）」といった接続フレーズ $p_{force}$ を挿入し、その条件下での正解トークン（Ground Truth Token） $y_{GT}$ の生成確率を計算する.

\begin{equation}
P_k(s_t) = P_M(y_{GT} \mid x, s_{1:t}, p_{force})
\end{equation}

この操作により、現在の推論ステップ $s_t$ が論理的に正解へ接続可能かを厳密に測定する.

\paragraph{アンサンブルによる教師信号のロバスト化}
単一モデルによる評価は、そのモデル固有のバイアスや過信（Overconfidence）の影響を受けやすい.
そこで、異なる系列のモデル群による合議を取り入れ、平均確信度 $P_{avg}(s_t) = \frac{1}{K} \sum_{k=1}^{K} P_k(s_t)$ を最終的な教師信号として用いる.
なお、比較対象として単一モデル（$K=1$）からの蒸留も行う.

\paragraph{Log-Sigmoid 変換による報酬設計}
指導モデルから得られる確信度は、特に論理が破綻したステップにおいて極めて小さな値（例えば $10^{-10}$ 以下）をとるため、そのままでは回帰学習が困難である.
そこで、対数確率に対し、データの分布特性に応じた中心化を行う Log-Sigmoid 変換を導入する.
ステップ $s_t$ に対する報酬 $r_t$ を以下の式で定義する.
\begin{equation}
r_t = \sigma(\alpha \cdot (\log P_{avg}(s_t) - \tau))
\end{equation}
ここで $\sigma$ はシグモイド関数、$\tau$ は正解パスと不正解パスの確率分布を分離する閾値（中心化パラメータ）、$\alpha$ は分布の幅を調整するスケーリング係数である.
生徒モデル（PRM）は、この $r_t$ を予測する回帰タスクとして学習する.

\subsection{学習ベースのスコア集計}

推論時（Best-of-N 探索）において、PRM は推論パスに対して可変長のステップスコア列 $V = (v_1, v_2, ..., v_T)$ を出力する.
単純な Min や Mean といった集計手法は外れ値（ノイズ）に弱いため、本研究ではスコア列全体の特徴を用いた学習ベース集計を行う.

\paragraph{特徴量抽出}
PRMの出力であるスコア列 $V$ から、以下の9次元の特徴量ベクトル $\phi(V)$ を抽出する.
\begin{itemize}
\item \textbf{基本統計量}: 最小値、平均値、最大値、標準偏差
\item \textbf{位置依存スコア}: 始点（First）、終点（Last）、および終盤3ステップの最小値（Min-Last-3）
\item \textbf{パス特性}: ステップ長、およびロジットの総和
\end{itemize}

\paragraph{集計モデル}
抽出された特徴量 $\phi(V)$ を入力とし、そのパスが最終的に正解か否かを 2 値分類する勾配ブースティング木（GBDT）を学習する.
推論時には、この分類器が出力する正解確率をパス全体の最終評価値として採用し、再順位付け（Reranking）を行う.